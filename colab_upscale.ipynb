{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400b5b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ“¦ Cell 1: å®‰è£…ä¾èµ– + æŒ‚è½½ Google Drive\n",
    "!pip install spandrel gdown -q\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"âœ… ä¾èµ–å®‰è£…å®Œæˆï¼ŒDrive å·²æŒ‚è½½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d38862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title âš™ï¸ Cell 2: é…ç½®å‚æ•°\n",
    "import os\n",
    "\n",
    "# ============ æ¨¡å‹é€‰æ‹© ============\n",
    "#@markdown ### æ¨¡å‹é€‰æ‹©\n",
    "MODEL_CHOICE = \"4x-Nomos8kDAT\"  #@param [\"4x-Nomos8kDAT\", \"4x-UltraSharp\", \"4x-Nomos8kSCSRFormer\"]\n",
    "\n",
    "# æ¨¡å‹ä¸‹è½½ä¿¡æ¯ (Google Drive ID + é¢„æœŸå¤§å° MB)\n",
    "MODEL_INFO = {\n",
    "    \"4x-UltraSharp\": {\n",
    "        \"gdrive_id\": None,  # ç”¨ HuggingFace\n",
    "        \"url\": \"https://huggingface.co/datasets/Kizi-Art/Upscale/resolve/main/4x-UltraSharp.pth\",\n",
    "        \"size_mb\": 67,\n",
    "    },\n",
    "    \"4x-Nomos8kDAT\": {\n",
    "        \"gdrive_id\": \"1JRwXYeuMBIsyeNfsTfeSs7gsHqCZD7xn\",\n",
    "        \"url\": None,\n",
    "        \"size_mb\": 295,\n",
    "    },\n",
    "    \"4x-Nomos8kSCSRFormer\": {\n",
    "        \"gdrive_id\": \"1VpMity5vqrEN7YFaPwawhVTdWYdJK8DG\",\n",
    "        \"url\": None,\n",
    "        \"size_mb\": 185,\n",
    "    },\n",
    "}\n",
    "\n",
    "MODEL_DIR = \"/content/models\"\n",
    "MODEL_NAME = f\"{MODEL_CHOICE}.pth\"\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, MODEL_NAME)\n",
    "EXPECTED_SIZE_MB = MODEL_INFO[MODEL_CHOICE][\"size_mb\"]\n",
    "\n",
    "# ============ æ”¾å¤§é…ç½® ============\n",
    "#@markdown ### æ”¾å¤§é…ç½®\n",
    "TARGET_SCALE = 8          #@param {type:\"slider\", min:4, max:16, step:4}\n",
    "MAX_SIDE_LENGTH = 8192    #@param {type:\"slider\", min:4096, max:16384, step:1024}\n",
    "TILE_SIZE = 512           #@param {type:\"slider\", min:128, max:1024, step:128}\n",
    "TILE_OVERLAP = 32         # åˆ†å—é‡å åƒç´ \n",
    "\n",
    "# ============ è¾“å‡ºæ ¼å¼ ============\n",
    "#@markdown ### è¾“å‡ºæ ¼å¼\n",
    "OUTPUT_FORMAT = \"jpg\"    #@param [\"png\", \"jpg\", \"both\"]\n",
    "\n",
    "# ============ è·¯å¾„é…ç½® (ç›´æ¥ç”¨ Drive) ============\n",
    "#@markdown ### è·¯å¾„é…ç½®\n",
    "DRIVE_BASE = \"/content/drive/MyDrive/upscale\"  #@param {type:\"string\"}\n",
    "INPUT_DIR = f\"{DRIVE_BASE}/input\"\n",
    "OUTPUT_DIR = f\"{DRIVE_BASE}/output\"\n",
    "\n",
    "# åˆ›å»ºç›®å½•\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ¤– æ¨¡å‹: {MODEL_CHOICE} (~{EXPECTED_SIZE_MB} MB)\")\n",
    "print(f\"ğŸ“ è¾“å…¥ç›®å½•: {INPUT_DIR}\")\n",
    "print(f\"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}\")\n",
    "print(f\"ğŸ¯ ç›®æ ‡æ”¾å¤§å€æ•°: {TARGET_SCALE}x\")\n",
    "print(f\"ğŸ§© åˆ†å—å¤§å°: {TILE_SIZE}\")\n",
    "print(f\"ğŸ’¾ è¾“å‡ºæ ¼å¼: {OUTPUT_FORMAT.upper()}\")\n",
    "print(\"\\nğŸ’¡ æç¤º: æŠŠå›¾ç‰‡æ”¾åˆ° Drive çš„ upscale/input æ–‡ä»¶å¤¹ï¼Œç„¶åè¿è¡Œåç»­ Cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3816d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ“‚ Cell 3: æ£€æŸ¥è¾“å…¥æ–‡ä»¶å¤¹\n",
    "import glob\n",
    "\n",
    "extensions = ['*.png', '*.jpg', '*.jpeg', '*.webp', '*.bmp']\n",
    "image_files = []\n",
    "for ext in extensions:\n",
    "    image_files.extend(glob.glob(os.path.join(INPUT_DIR, ext)))\n",
    "    image_files.extend(glob.glob(os.path.join(INPUT_DIR, ext.upper())))\n",
    "\n",
    "if not image_files:\n",
    "    print(f\"âŒ è¾“å…¥æ–‡ä»¶å¤¹ä¸ºç©º: {INPUT_DIR}\")\n",
    "    print(\"ğŸ’¡ è¯·å…ˆæŠŠå›¾ç‰‡æ”¾åˆ° Google Drive çš„ upscale/input æ–‡ä»¶å¤¹\")\n",
    "else:\n",
    "    print(f\"âœ… æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡:\")\n",
    "\n",
    "    for f in image_files:\n",
    "        print(f\"  ğŸ“· {os.path.basename(f)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251df689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ“¥ Cell 4: ä¸‹è½½æ¨¡å‹\n",
    "import os\n",
    "import gdown\n",
    "\n",
    "def download_model():\n",
    "    info = MODEL_INFO[MODEL_CHOICE]\n",
    "    \n",
    "    if info[\"gdrive_id\"]:\n",
    "        # ä½¿ç”¨ gdown ä» Google Drive ä¸‹è½½\n",
    "        print(f\"â¬‡ï¸ æ­£åœ¨ä» Google Drive ä¸‹è½½ {MODEL_NAME}...\")\n",
    "        gdown.download(id=info[\"gdrive_id\"], output=MODEL_PATH, quiet=False)\n",
    "    else:\n",
    "        # ä½¿ç”¨ wget ä» URL ä¸‹è½½\n",
    "        print(f\"â¬‡ï¸ æ­£åœ¨ä¸‹è½½ {MODEL_NAME}...\")\n",
    "        url = info[\"url\"]\n",
    "        !wget -q --show-progress -O \"{MODEL_PATH}\" \"{url}\"\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸‹è½½\n",
    "need_download = False\n",
    "min_size = EXPECTED_SIZE_MB * 0.9  # å…è®¸ 10% è¯¯å·®\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    need_download = True\n",
    "else:\n",
    "    size_mb = os.path.getsize(MODEL_PATH) / (1024 * 1024)\n",
    "    if size_mb < min_size:\n",
    "        print(f\"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´ ({size_mb:.1f} MB < {min_size:.0f} MB)ï¼Œé‡æ–°ä¸‹è½½...\")\n",
    "        os.remove(MODEL_PATH)\n",
    "        need_download = True\n",
    "\n",
    "if need_download:\n",
    "    download_model()\n",
    "    print(f\"âœ… æ¨¡å‹å·²ä¸‹è½½åˆ° {MODEL_PATH}\")\n",
    "else:\n",
    "    print(f\"âœ… æ¨¡å‹å·²å­˜åœ¨: {MODEL_PATH}\")\n",
    "\n",
    "# æ£€æŸ¥æ–‡ä»¶å¤§å°\n",
    "size_mb = os.path.getsize(MODEL_PATH) / (1024 * 1024)\n",
    "print(f\"ğŸ“¦ æ¨¡å‹å¤§å°: {size_mb:.1f} MB (é¢„æœŸ: ~{EXPECTED_SIZE_MB} MB)\")\n",
    "\n",
    "if size_mb < min_size:\n",
    "    print(f\"âŒ æ¨¡å‹æ–‡ä»¶å¯èƒ½æŸåï¼Œè¯·åˆ é™¤åé‡æ–°ä¸‹è½½\")\n",
    "    print(f\"   è¿è¡Œ: !rm \\\"{MODEL_PATH}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ”§ Cell 5: åŠ è½½æ¨¡å‹\n",
    "import torch\n",
    "import spandrel\n",
    "\n",
    "print(\"ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...\")\n",
    "\n",
    "# æ£€æŸ¥ CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "# åŠ è½½æ¨¡å‹\n",
    "try:\n",
    "    model_descriptor = spandrel.ModelLoader(device=device).load_from_file(MODEL_PATH)\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
    "    print(f\"âš ï¸ æ¨¡å‹æ–‡ä»¶å¯èƒ½æŸåæˆ–ä¸‹è½½ä¸å®Œæ•´\")\n",
    "    \n",
    "    # åˆ é™¤æŸåçš„æ¨¡å‹æ–‡ä»¶\n",
    "    if os.path.exists(MODEL_PATH):\n",
    "        os.remove(MODEL_PATH)\n",
    "        print(f\"ğŸ—‘ï¸ å·²åˆ é™¤æŸåçš„æ¨¡å‹æ–‡ä»¶: {MODEL_PATH}\")\n",
    "    \n",
    "    print(\"\\nğŸ’¡ è¯·é‡æ–°è¿è¡Œ Cell 4 ä¸‹è½½æ¨¡å‹\")\n",
    "    print(\"ğŸ”Œ æ­£åœ¨æ–­å¼€è¿è¡Œæ—¶ä»¥èŠ‚çœç‚¹æ•°...\")\n",
    "    \n",
    "    from google.colab import runtime\n",
    "    runtime.unassign()\n",
    "    raise  # ç¡®ä¿åœæ­¢æ‰§è¡Œ\n",
    "\n",
    "model = model_descriptor.model\n",
    "\n",
    "# åªæœ‰ ESRGAN æ¶æ„æ”¯æŒ FP16ï¼ŒDAT/SRFormer éœ€è¦ FP32\n",
    "USE_FP16 = \"UltraSharp\" in MODEL_CHOICE  # ESRGAN æ¶æ„\n",
    "if USE_FP16:\n",
    "    model.half()\n",
    "    print(\"âš¡ ä½¿ç”¨ FP16 (åŠç²¾åº¦)\")\n",
    "else:\n",
    "    print(\"ğŸ”¢ ä½¿ç”¨ FP32 (å…¨ç²¾åº¦) - DAT/SRFormer æ¶æ„éœ€è¦\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "MODEL_SCALE = model_descriptor.scale  # æ¨¡å‹åŸç”Ÿæ”¾å¤§å€æ•° (4x)\n",
    "\n",
    "print(f\"âœ… æ¨¡å‹åŠ è½½å®Œæˆ\")\n",
    "print(f\"ğŸ“ æ¨¡å‹åŸç”Ÿå€æ•°: {MODEL_SCALE}x\")\n",
    "print(f\"ğŸ¯ ç›®æ ‡å€æ•°: {TARGET_SCALE}x â†’ éœ€è¦è¿­ä»£ {TARGET_SCALE // MODEL_SCALE} æ¬¡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1be492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ› ï¸ Cell 6: å®šä¹‰å¤„ç†å‡½æ•°\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import math\n",
    "\n",
    "def pil_to_torch(img: Image.Image) -> torch.Tensor:\n",
    "    \"\"\"PIL Image (RGB) â†’ Torch Tensor (NCHW, BGR, 0~1)\"\"\"\n",
    "    img_np = np.array(img).astype(np.float32) / 255.0\n",
    "    # RGB â†’ BGR\n",
    "    if img_np.ndim == 3 and img_np.shape[2] == 3:\n",
    "        img_np = img_np[:, :, ::-1].copy()  # copy() è§£å†³è´Ÿ stride é—®é¢˜\n",
    "    # HWC â†’ CHW â†’ NCHW\n",
    "    img_tensor = torch.from_numpy(img_np.transpose(2, 0, 1).copy()).unsqueeze(0)\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    if USE_FP16:\n",
    "        img_tensor = img_tensor.half()\n",
    "    return img_tensor\n",
    "\n",
    "def torch_to_pil(tensor: torch.Tensor) -> Image.Image:\n",
    "    \"\"\"Torch Tensor (NCHW, BGR) â†’ PIL Image (RGB)\"\"\"\n",
    "    img_np = tensor.squeeze(0).float().cpu().clamp(0, 1).numpy()\n",
    "    # CHW â†’ HWC\n",
    "    img_np = img_np.transpose(1, 2, 0)\n",
    "    # BGR â†’ RGB\n",
    "    img_np = img_np[:, :, ::-1].copy()  # copy() è§£å†³è´Ÿ stride é—®é¢˜\n",
    "    img_np = (img_np * 255).astype(np.uint8)\n",
    "    return Image.fromarray(img_np)\n",
    "\n",
    "@torch.inference_mode()\n",
    "def tiled_upscale(img: Image.Image, tile_size: int = 512, overlap: int = 32) -> Image.Image:\n",
    "    \"\"\"\n",
    "    åˆ†å—æ”¾å¤§ï¼Œé¿å…æ˜¾å­˜çˆ†ç‚¸\n",
    "    å‚è€ƒ: stable-diffusion-webui/modules/upscaler_utils.py\n",
    "    \"\"\"\n",
    "    width, height = img.size\n",
    "    \n",
    "    # è®¡ç®—åˆ†å—æ•°é‡\n",
    "    tiles_x = math.ceil(width / (tile_size - overlap))\n",
    "    tiles_y = math.ceil(height / (tile_size - overlap))\n",
    "    \n",
    "    # è¾“å‡ºå°ºå¯¸\n",
    "    out_width = width * MODEL_SCALE\n",
    "    out_height = height * MODEL_SCALE\n",
    "    output = Image.new('RGB', (out_width, out_height))\n",
    "    \n",
    "    # æ”¾å¤§åçš„ overlap\n",
    "    scaled_overlap = overlap * MODEL_SCALE\n",
    "    \n",
    "    for y in range(tiles_y):\n",
    "        for x in range(tiles_x):\n",
    "            # è®¡ç®—è¾“å…¥ tile çš„åæ ‡\n",
    "            x1 = x * (tile_size - overlap)\n",
    "            y1 = y * (tile_size - overlap)\n",
    "            x2 = min(x1 + tile_size, width)\n",
    "            y2 = min(y1 + tile_size, height)\n",
    "            \n",
    "            # ç¡®ä¿ tile å°ºå¯¸ä¸€è‡´ï¼ˆè¾¹ç¼˜æƒ…å†µï¼‰\n",
    "            if x2 - x1 < tile_size and x1 > 0:\n",
    "                x1 = max(0, x2 - tile_size)\n",
    "            if y2 - y1 < tile_size and y1 > 0:\n",
    "                y1 = max(0, y2 - tile_size)\n",
    "            \n",
    "            # è£åˆ‡ tile\n",
    "            tile = img.crop((x1, y1, x2, y2))\n",
    "            \n",
    "            # æ”¾å¤§\n",
    "            tile_tensor = pil_to_torch(tile)\n",
    "            upscaled_tensor = model(tile_tensor)\n",
    "            upscaled_tile = torch_to_pil(upscaled_tensor)\n",
    "            \n",
    "            # è®¡ç®—è¾“å‡ºåæ ‡\n",
    "            out_x1 = x1 * MODEL_SCALE\n",
    "            out_y1 = y1 * MODEL_SCALE\n",
    "            out_x2 = x2 * MODEL_SCALE\n",
    "            out_y2 = y2 * MODEL_SCALE\n",
    "            \n",
    "            # è®¡ç®—æœ‰æ•ˆåŒºåŸŸï¼ˆå»é™¤é‡å éƒ¨åˆ†ï¼Œé™¤äº†è¾¹ç¼˜ï¼‰\n",
    "            paste_x1 = 0 if x == 0 else scaled_overlap // 2\n",
    "            paste_y1 = 0 if y == 0 else scaled_overlap // 2\n",
    "            paste_x2 = upscaled_tile.width if x == tiles_x - 1 else upscaled_tile.width - scaled_overlap // 2\n",
    "            paste_y2 = upscaled_tile.height if y == tiles_y - 1 else upscaled_tile.height - scaled_overlap // 2\n",
    "            \n",
    "            # è£åˆ‡æœ‰æ•ˆåŒºåŸŸ\n",
    "            valid_tile = upscaled_tile.crop((paste_x1, paste_y1, paste_x2, paste_y2))\n",
    "            \n",
    "            # ç²˜è´´åˆ°è¾“å‡º\n",
    "            final_x = out_x1 + paste_x1\n",
    "            final_y = out_y1 + paste_y1\n",
    "            output.paste(valid_tile, (final_x, final_y))\n",
    "    \n",
    "    return output\n",
    "\n",
    "def multi_scale_upscale(img: Image.Image, target_scale: int) -> Image.Image:\n",
    "    \"\"\"\n",
    "    æ”¾å¤§å›¾ç‰‡åˆ°ç›®æ ‡å€æ•°ï¼Œä¸è¶…è¿‡ MAX_SIDE_LENGTH\n",
    "    å‚è€ƒ: stable-diffusion-webui Extras é€»è¾‘\n",
    "    \"\"\"\n",
    "    # ä¸­é—´å›¾æœ€å¤§åƒç´ æ•°é™åˆ¶ (é˜²æ­¢è®¡ç®—æ—¶é—´çˆ†ç‚¸)\n",
    "    # 1äº¿åƒç´  â‰ˆ 10000x10000ï¼ŒDAT å¤„ç†çº¦éœ€ 2-3 åˆ†é’Ÿ\n",
    "    MAX_INTERMEDIATE_PIXELS = 100_000_000  # 1äº¿åƒç´ \n",
    "    \n",
    "    orig_w, orig_h = img.size\n",
    "    max_orig_side = max(orig_w, orig_h)\n",
    "    \n",
    "    # è®¡ç®—å®é™…å¯ç”¨çš„æ”¾å¤§å€æ•°ï¼ˆä¸è¶…è¿‡ MAX_SIDE_LENGTHï¼‰\n",
    "    max_possible_scale = MAX_SIDE_LENGTH / max_orig_side\n",
    "    actual_scale = min(target_scale, max_possible_scale)\n",
    "    \n",
    "    # è®¡ç®—ç›®æ ‡å°ºå¯¸ (å¯¹é½åˆ°8åƒç´ ï¼Œå‚è€ƒ SD WebUI)\n",
    "    target_w = int((orig_w * actual_scale) // 8 * 8)\n",
    "    target_h = int((orig_h * actual_scale) // 8 * 8)\n",
    "    \n",
    "    print(f\"  ğŸ¯ ç›®æ ‡å°ºå¯¸: {target_w}x{target_h} ({actual_scale:.2f}x)\")\n",
    "    \n",
    "    # å¦‚æœåŸå›¾å·²ç»å¤Ÿå¤§\n",
    "    if actual_scale <= 1:\n",
    "        print(f\"  âš ï¸ åŸå›¾å·²æ¥è¿‘æœ€å¤§è¾¹é•¿ï¼Œæ— éœ€æ”¾å¤§\")\n",
    "        return img\n",
    "    \n",
    "    # è¿­ä»£æ”¾å¤§ï¼Œä½†é™åˆ¶ä¸­é—´åƒç´ æ•°\n",
    "    current = img\n",
    "    current_scale = 1.0\n",
    "    iteration = 0\n",
    "    \n",
    "    while current_scale < actual_scale:\n",
    "        # æ£€æŸ¥ä¸‹ä¸€æ¬¡æ”¾å¤§åçš„å°ºå¯¸å’Œåƒç´ æ•°\n",
    "        next_w = current.width * MODEL_SCALE\n",
    "        next_h = current.height * MODEL_SCALE\n",
    "        next_pixels = next_w * next_h\n",
    "        \n",
    "        # å¦‚æœä¸‹ä¸€æ¬¡æ”¾å¤§ä¼šè¶…è¿‡åƒç´ æ•°é™åˆ¶ï¼Œæå‰åœæ­¢\n",
    "        if next_pixels > MAX_INTERMEDIATE_PIXELS:\n",
    "            print(f\"  âš ï¸ ä¸‹æ¬¡æ”¾å¤§ ({next_w}x{next_h} = {next_pixels/1e6:.0f}M åƒç´ ) è¶…è¿‡é™åˆ¶ï¼Œè·³è¿‡\")\n",
    "            break\n",
    "        \n",
    "        iteration += 1\n",
    "        print(f\"  ğŸ“ è¿­ä»£ {iteration}: {current.width}x{current.height} â†’ {next_w}x{next_h}\")\n",
    "        current = tiled_upscale(current, TILE_SIZE, TILE_OVERLAP)\n",
    "        current_scale *= MODEL_SCALE\n",
    "    \n",
    "    # æœ€å resize åˆ°ç²¾ç¡®çš„ç›®æ ‡å°ºå¯¸ (åªç¼©å°ï¼Œä¸æ”¾å¤§)\n",
    "    if current.size != (target_w, target_h):\n",
    "        if current.width >= target_w and current.height >= target_h:\n",
    "            # ESRGAN ç»“æœæ¯”ç›®æ ‡å¤§ï¼Œç¼©å°åˆ°ç›®æ ‡å°ºå¯¸\n",
    "            print(f\"  ğŸ”„ Resize (ç¼©å°): {current.width}x{current.height} â†’ {target_w}x{target_h}\")\n",
    "            current = current.resize((target_w, target_h), Image.LANCZOS)\n",
    "        else:\n",
    "            # ESRGAN ç»“æœæ¯”ç›®æ ‡å°ï¼Œä¸ç”¨ä¼ ç»Ÿæ’å€¼æ”¾å¤§ï¼Œç›´æ¥è¾“å‡º\n",
    "            print(f\"  âš ï¸ è·³è¿‡ä¼ ç»Ÿæ”¾å¤§ï¼Œè¾“å‡º ESRGAN ç»“æœ: {current.width}x{current.height}\")\n",
    "    \n",
    "    return current\n",
    "\n",
    "print(\"âœ… å¤„ç†å‡½æ•°å·²å®šä¹‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca0d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸš€ Cell 7: æ‰¹é‡å¤„ç† â†’ ä¿å­˜åˆ° Drive\n",
    "import glob\n",
    "import time\n",
    "\n",
    "# è·å–æ‰€æœ‰å›¾ç‰‡\n",
    "extensions = ['*.png', '*.jpg', '*.jpeg', '*.webp', '*.bmp']\n",
    "image_files = []\n",
    "for ext in extensions:\n",
    "    image_files.extend(glob.glob(os.path.join(INPUT_DIR, ext)))\n",
    "    image_files.extend(glob.glob(os.path.join(INPUT_DIR, ext.upper())))\n",
    "\n",
    "if not image_files:\n",
    "    print(\"âŒ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡ï¼Œè¯·å…ˆè¿è¡Œ Cell 3 ä¸Šä¼ å›¾ç‰‡\")\n",
    "else:\n",
    "    print(f\"ğŸ“· æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡\")\n",
    "    print(f\"ğŸ¯ ç›®æ ‡å€æ•°: {TARGET_SCALE}x\")\n",
    "    print(f\"ğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    failed = False\n",
    "    \n",
    "    for idx, img_path in enumerate(image_files, 1):\n",
    "        filename = os.path.basename(img_path)\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        \n",
    "        print(f\"\\n[{idx}/{len(image_files)}] å¤„ç†: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            # åŠ è½½å›¾ç‰‡\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            orig_size = img.size\n",
    "            print(f\"  ğŸ“ åŸå§‹å°ºå¯¸: {orig_size[0]}x{orig_size[1]}\")\n",
    "            \n",
    "            # æ”¾å¤§\n",
    "            upscaled = multi_scale_upscale(img, TARGET_SCALE)\n",
    "            final_size = upscaled.size\n",
    "            print(f\"  âœ… æœ€ç»ˆå°ºå¯¸: {final_size[0]}x{final_size[1]}\")\n",
    "            \n",
    "            # æ ¹æ®é…ç½®ä¿å­˜\n",
    "            if OUTPUT_FORMAT in (\"png\", \"both\"):\n",
    "                png_path = os.path.join(OUTPUT_DIR, f\"{name}.png\")\n",
    "                upscaled.save(png_path)\n",
    "                print(f\"  ğŸ’¾ å·²ä¿å­˜: {name}.png\")\n",
    "            \n",
    "            if OUTPUT_FORMAT in (\"jpg\", \"both\"):\n",
    "                # JPG: quality=92 + 4:4:4 â‰ˆ Photoshop è´¨é‡ 11/12\n",
    "                jpg_path = os.path.join(OUTPUT_DIR, f\"{name}.jpg\")\n",
    "                upscaled.save(jpg_path, quality=92, subsampling=0)\n",
    "                print(f\"  ğŸ’¾ å·²ä¿å­˜: {name}.jpg\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ é”™è¯¯: {e}\")\n",
    "            failed = True\n",
    "            break  # é‡åˆ°é”™è¯¯ç«‹å³åœæ­¢\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    \n",
    "    if failed:\n",
    "        print(f\"âŒ å¤„ç†å¤±è´¥ï¼Œè€—æ—¶: {elapsed:.1f} ç§’\")\n",
    "        print(\"ğŸ”Œ æ­£åœ¨æ–­å¼€è¿è¡Œæ—¶ä»¥èŠ‚çœç‚¹æ•°...\")\n",
    "        from google.colab import runtime\n",
    "        runtime.unassign()\n",
    "    else:\n",
    "        print(f\"ğŸ‰ å…¨éƒ¨å®Œæˆ! è€—æ—¶: {elapsed:.1f} ç§’\")\n",
    "        print(f\"ğŸ“ è¾“å‡ºä½ç½®: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a87b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ğŸ”Œ Cell 8: æ–­å¼€è¿è¡Œæ—¶\n",
    "from google.colab import runtime\n",
    "\n",
    "print(\"âš ï¸ å³å°†æ–­å¼€è¿è¡Œæ—¶...\")\n",
    "print(\"ğŸ“ è¾“å‡ºå·²ä¿å­˜åˆ° Google Driveï¼Œæ— éœ€ç­‰å¾…ä¸‹è½½\")\n",
    "\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
